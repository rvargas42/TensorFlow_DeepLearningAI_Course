{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNnNyVXtNfx1U1Em9oR2ez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvargas42/TensorFlow_DeepLearningAI_Course/blob/main/C1/C1_W2_ComputerVision_Callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Computer Vision\n",
        "\n",
        "\n",
        "> CV is the field of using a computer to recognise objects inside an image or video. We use a dataset of images labeled as tshirts to train a neural network.\n",
        "\n"
      ],
      "metadata": {
        "id": "KdhAidVxSxzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZaIdFPT2Es",
        "outputId": "9e9313da-4562-4c82-f480-2e6c0294f782"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 1.   Loading Data\n",
        "\n"
      ],
      "metadata": {
        "id": "clN4qpaWTQYQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW66AZsVRx7G",
        "outputId": "a376e3c7-53a0-46ab-98f7-2c398392a6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_img, train_labels), (test_img, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Visualizing Data"
      ],
      "metadata": {
        "id": "W2Pi3rHnWeOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = 42\n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "print(f'Label: {train_labels[index]}')\n",
        "print(f'\\nImage Pixel Array:\\n {train_img[index]}')\n",
        "\n",
        "plt.imshow(train_img[index], cmap='Greys')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "kWIr86yyWeDb",
        "outputId": "de470900-6507-41c0-a4ab-defeaeef406f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9\n",
            "\n",
            "Image Pixel Array:\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187  26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237 255 240 139  83  64  43  60  54   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234 238 246 252 254 255 248 255 187   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237 235 232 230 234 234 233 249 171   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239 238 239 240 239 242 238 248 192   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241 240 241 243 243 241 227 250 209   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241 242 241 242 242 238 238 242 253   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241 244 243 243 244 243 239 235 255  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241 242 242 242 243 239 237 235 253 106   0]\n",
            " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242 241 240 240 240 235 237 236 246 234   0]\n",
            " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237 236 238 239 239 239 239 239 237 255   0]\n",
            " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231 232 237 240 236 238 239 239 235 251  62]\n",
            " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230 228 230 233 232 235 233 234 235 255  58]\n",
            " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250 251 252 254 254 252 254 252 235 255   0]\n",
            " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227 219 202 193 189 186 181 171 165 190  42]\n",
            " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184 152 171 165 162 162 167 168 157 192  78]\n",
            " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0   0 209 231 218 222 224 227 217 229  93]\n",
            " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0   0  72  51  53  37  34  29  31   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7abe2c252890>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Building Model"
      ],
      "metadata": {
        "id": "sxs8hJsvVDkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **3.1 Normalizing Data**\n",
        "\n"
      ],
      "metadata": {
        "id": "QS-at-0dXjsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing Data: this turns data to values from 0 to 1.\n",
        "train_img = train_img/255.0\n",
        "test_img = test_img/255.0"
      ],
      "metadata": {
        "id": "L4kdjOqEXUke"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **3.2 Initialize Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "-Rz2CY0mXqVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(), #this is the size of the image, 28x28 pixels with values form 0 to 255 (1byte)\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu), #relu activation function filters negative values.\n",
        "        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Iousb1TnU_2K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **3.3 Compile Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "Vg9uT4QFYRtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_img, train_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x97yV4YoX-nG",
        "outputId": "f7aacb18-c31b-4b77-9ad5-77387aaed471"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.4993 - accuracy: 0.8255\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3746 - accuracy: 0.8646\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3382 - accuracy: 0.8756\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3143 - accuracy: 0.8842\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2954 - accuracy: 0.8908\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7abe2bd319f0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_img, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2WHikVvYuFW",
        "outputId": "fcbbef00-2a9a-47d8-988d-d638a4ca6c77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3365 - accuracy: 0.8779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33647844195365906, 0.8779000043869019]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Implement CallBack function/class\n",
        "\n",
        "> this will control desired training accuracy while trining and avoid loosing time."
      ],
      "metadata": {
        "id": "31b5q8pyZ2L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CallBack(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}): #this is an standard function for .Callback\n",
        "        if(logs.get('loss')<0.4):\n",
        "            print(\"\\nLoss is low -> Cancelling further training\")\n",
        "            self.model.stop_training = True #acceses Callback class and sets stop_training = True"
      ],
      "metadata": {
        "id": "WSik5ZidZQSF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = CallBack()"
      ],
      "metadata": {
        "id": "MeiwEwQBamp5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_img, train_labels, epochs=5, callbacks = [callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng4pz6yMayCf",
        "outputId": "021fc986-51ef-48af-d7f7-ce0b333b14cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.8948\n",
            "Loss is low -> Cancelling further training\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2829 - accuracy: 0.8949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7abe2fba7670>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QoMLFIgJa9Wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}