{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIhrRWG7Arw+JqwHDT2Huu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvargas42/TensorFlow_DeepLearningAI_Course/blob/main/C1/C1_W1_Intro_NeuralNetworks_GradientDescent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Networks Introduction"
      ],
      "metadata": {
        "id": "3CFD8DW8p2xj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCcSDkwhpKrO",
        "outputId": "8b123f2f-3cfc-4202-e8bb-1311b66ebe1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Defining and compiling a Neural Network\n",
        "\n",
        "  - In this code we define a neural network with a sequential architecture and one layer and one neuron."
      ],
      "metadata": {
        "id": "89QYqfw7qFAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [keras.layers.Dense(units=1, input_shape=[1])]\n",
        ")"
      ],
      "metadata": {
        "id": "QES6AXPGp2OG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")"
      ],
      "metadata": {
        "id": "x1dHbaSIqmqr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We are using Stochastic Gradient Descent to optimize our model, and a loss function that is optimzed of MSE*.\n",
        "\n",
        "\n",
        "\n",
        "> My understanging: Stochastic Gradient Descent does gradient descent optimization on only a subset of the traning data. It is a more practical algorithm that avoids going through every point of data. This optimizer algorithm takes the partial derivatives of each feature and finds global minimums for the loss function.\n",
        "\n",
        "\"*In machine/deep learning terminology, it’s the task of minimizing the cost/loss function J(w) parameterized by the model’s parameters w ∈ R^d.*\"\n"
      ],
      "metadata": {
        "id": "k6ltgAIXqz-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Example/Pracice. Computing a Basic Gradient Descent on a Linear Regression.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Obtain Data\n",
        "\n",
        "\n",
        "> Define: Learning Rate, and Epochs\n",
        "\n",
        "\n",
        "> Perform iterations on loss function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g8jimqY_tDxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "X = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0])\n",
        "y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0])\n",
        "#defining model and alg params\n",
        "n = 5\n",
        "sample_size = 1\n",
        "L = .01\n",
        "epochs = 500\n",
        "m = .0\n",
        "b = .0\n",
        "loss = .0\n",
        "for i in range(epochs):\n",
        "    idx = np.random.choice(n, sample_size, replace=False)\n",
        "    X_sample = X[idx]\n",
        "    y_sample = y[idx]\n",
        "\n",
        "    y_pred = m * X_sample + b\n",
        "    D_m = (-2/sample_size)* sum(X_sample * (y_sample - y_pred))\n",
        "    D_b = (-2 / sample_size) * sum(y_sample - y_pred)\n",
        "\n",
        "    m = m - L * D_m\n",
        "    b = b - L * D_b\n",
        "    loss += (y_pred-y_sample)**2 #MSE is our loss function\n",
        "    print(f\"epoch {i}, m = {m}, b = {b}/n\")\n",
        "    print(f\"Loss: {loss/i}\")\n",
        "\n",
        "print(\"y = {0}x + {1}\".format(m, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkCpN23yuB9u",
        "outputId": "c5123d51-afd3-497c-e30c-7d73a72c93f7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, m = 0.3, b = 0.1/n\n",
            "Loss: [inf]\n",
            "epoch 1, m = 0.54, b = 0.18/n\n",
            "Loss: [41.]\n",
            "epoch 2, m = 0.5928, b = 0.12719999999999998/n\n",
            "Loss: [23.9848]\n",
            "epoch 3, m = 0.5928, b = 0.10465599999999997/n\n",
            "Loss: [16.41339328]\n",
            "epoch 4, m = 0.77981664, b = 0.16699487999999998/n\n",
            "Loss: [14.73887993]\n",
            "epoch 5, m = 0.77981664, b = 0.1436549824/n\n",
            "Loss: [12.06347936]\n",
            "epoch 6, m = 0.9308303458559999, b = 0.193992884352/n\n",
            "Loss: [11.10869295]\n",
            "epoch 7, m = 0.9760935966259199, b = 0.14872963358208/n\n",
            "Loss: [10.25343749]\n",
            "epoch 8, m = 1.0914729712183295, b = 0.1871894251128832/n\n",
            "Loss: [9.43399391]\n",
            "epoch 9, m = 1.0858997232917054, b = 0.18161617718625894/n\n",
            "Loss: [8.39440045]\n",
            "epoch 10, m = 1.1117630983409186, b = 0.19454786471086555/n\n",
            "Loss: [7.59676754]\n",
            "epoch 11, m = 1.105636879079883, b = 0.18842164544982987/n\n",
            "Loss: [6.91468198]\n",
            "epoch 12, m = 1.147292574407282, b = 0.14676595012243093/n\n",
            "Loss: [6.69995785]\n",
            "epoch 13, m = 1.1696385304498023, b = 0.15793892814369104/n\n",
            "Loss: [6.20858329]\n",
            "epoch 14, m = 1.1897498908880704, b = 0.16799460836282512/n\n",
            "Loss: [5.78316961]\n",
            "epoch 15, m = 1.1897498908880704, b = 0.1446347161955686/n\n",
            "Loss: [5.4885724]\n",
            "epoch 16, m = 1.2669168275564835, b = 0.17035702841837302/n\n",
            "Loss: [5.24891746]\n",
            "epoch 17, m = 1.2787492002152299, b = 0.1762732147477462/n\n",
            "Loss: [4.94530485]\n",
            "epoch 18, m = 1.3379979512916238, b = 0.1960227984398775/n\n",
            "Loss: [4.72473876]\n",
            "epoch 19, m = 1.3751584482345889, b = 0.1588623014969124/n\n",
            "Loss: [4.657766]\n",
            "epoch 20, m = 1.4180981894625482, b = 0.17317554857289882/n\n",
            "Loss: [4.45048633]\n",
            "epoch 21, m = 1.4524499824449155, b = 0.18462614623368795/n\n",
            "Loss: [4.25416748]\n",
            "epoch 22, m = 1.4799314168308095, b = 0.19378662436231925/n\n",
            "Loss: [4.07033195]\n",
            "epoch 23, m = 1.4737854385098519, b = 0.19071363520184048/n\n",
            "Loss: [3.89438744]\n",
            "epoch 24, m = 1.4682540580209902, b = 0.1879479449574096/n\n",
            "Loss: [3.73291807]\n",
            "epoch 25, m = 1.4632758155810146, b = 0.1854588237374218/n\n",
            "Loss: [3.58422092]\n",
            "epoch 26, m = 1.4887586393521866, b = 0.1939530983278125/n\n",
            "Loss: [3.45330403]\n",
            "epoch 27, m = 1.4887586393521866, b = 0.17007403636125623/n\n",
            "Loss: [3.37820106]\n",
            "epoch 28, m = 1.4887586393521866, b = 0.14667255563403112/n\n",
            "Loss: [3.3064465]\n",
            "epoch 29, m = 1.4760500154524623, b = 0.13396393173430676/n\n",
            "Loss: [3.2063543]\n",
            "epoch 30, m = 1.472607456946893, b = 0.13224265248152214/n\n",
            "Loss: [3.09972273]\n",
            "epoch 31, m = 1.4996035555475609, b = 0.14124135201507812/n\n",
            "Loss: [3.00626204]\n",
            "epoch 32, m = 1.4996035555475609, b = 0.11841652497477656/n\n",
            "Loss: [2.95301735]\n",
            "epoch 33, m = 1.4996035555475609, b = 0.09604819447528103/n\n",
            "Loss: [2.90143669]\n",
            "epoch 34, m = 1.523912023880483, b = 0.10415101725292175/n\n",
            "Loss: [2.82092794]\n",
            "epoch 35, m = 1.543358798546821, b = 0.11063327547503432/n\n",
            "Loss: [2.7433314]\n",
            "epoch 36, m = 1.535464763644074, b = 0.1066862580236608/n\n",
            "Loss: [2.66820963]\n",
            "epoch 37, m = 1.535464763644074, b = 0.08455253286318759/n\n",
            "Loss: [2.62919732]\n",
            "epoch 38, m = 1.5540079542163494, b = 0.09073359638727939/n\n",
            "Loss: [2.56252144]\n",
            "epoch 39, m = 1.5460579740235503, b = 0.08675860629087982/n\n",
            "Loss: [2.49782862]\n",
            "epoch 40, m = 1.5625620223218584, b = 0.09225995572364921/n\n",
            "Loss: [2.43727446]\n",
            "epoch 41, m = 1.5494655827609483, b = 0.07916351616273906/n\n",
            "Loss: [2.38828708]\n",
            "epoch 42, m = 1.580059541428984, b = 0.04856955749470324/n\n",
            "Loss: [2.38713681]\n",
            "epoch 43, m = 1.6094297417502983, b = 0.01919935717338886/n\n",
            "Loss: [2.38177366]\n",
            "epoch 44, m = 1.5999073881233388, b = 0.014438180359909146/n\n",
            "Loss: [2.32893045]\n",
            "epoch 45, m = 1.5913372698590753, b = 0.010153121227777416/n\n",
            "Loss: [2.27819653]\n",
            "epoch 46, m = 1.6197135868864494, b = -0.018223195799596626/n\n",
            "Loss: [2.27243222]\n",
            "epoch 47, m = 1.6076837790647123, b = -0.03025300362133368/n\n",
            "Loss: [2.23178028]\n",
            "epoch 48, m = 1.6076837790647123, b = -0.049647943548907/n\n",
            "Loss: [2.20487671]\n",
            "epoch 49, m = 1.5965230623543962, b = -0.06080866025922311/n\n",
            "Loss: [2.16623441]\n",
            "epoch 50, m = 1.6127974307461583, b = -0.05538387079530241/n\n",
            "Loss: [2.12438114]\n",
            "epoch 51, m = 1.625816925459568, b = -0.05104403922416586/n\n",
            "Loss: [2.08364985]\n",
            "epoch 52, m = 1.61432146773486, b = -0.0625394969488739/n\n",
            "Loss: [2.04993281]\n",
            "epoch 53, m = 1.6076773301940261, b = -0.06586156571929082/n\n",
            "Loss: [2.01177541]\n",
            "epoch 54, m = 1.6222471047022589, b = -0.061004974216546576/n\n",
            "Loss: [1.97561228]\n",
            "epoch 55, m = 1.6485820631238828, b = -0.08733993263817047/n\n",
            "Loss: [1.97121615]\n",
            "epoch 56, m = 1.657077687719874, b = -0.08450805777284004/n\n",
            "Loss: [1.93637387]\n",
            "epoch 57, m = 1.657077687719874, b = -0.10281789661738323/n\n",
            "Loss: [1.91710636]\n",
            "epoch 58, m = 1.681879776033129, b = -0.1276199849306381/n\n",
            "Loss: [1.91056761]\n",
            "epoch 59, m = 1.670794580211079, b = -0.1387051807526879/n\n",
            "Loss: [1.88339195]\n",
            "epoch 60, m = 1.6626792210243002, b = -0.1427628603460773/n\n",
            "Loss: [1.85268812]\n",
            "epoch 61, m = 1.6865703793968927, b = -0.16665401871866975/n\n",
            "Loss: [1.84570911]\n",
            "epoch 62, m = 1.6865703793968927, b = -0.18332093834429636/n\n",
            "Loss: [1.82714066]\n",
            "epoch 63, m = 1.6765053905758407, b = -0.19338592716534828/n\n",
            "Loss: [1.80215843]\n",
            "epoch 64, m = 1.699107564221017, b = -0.2159881008105245/n\n",
            "Loss: [1.79395511]\n",
            "epoch 65, m = 1.699107564221017, b = -0.231668338794314/n\n",
            "Loss: [1.77581233]\n",
            "epoch 66, m = 1.699107564221017, b = -0.24703497201842772/n\n",
            "Loss: [1.75785053]\n",
            "epoch 67, m = 1.6900661123769651, b = -0.25607642386247953/n\n",
            "Loss: [1.73466425]\n",
            "epoch 68, m = 1.7012187975808601, b = -0.25235886212784786/n\n",
            "Loss: [1.70966258]\n",
            "epoch 69, m = 1.7012187975808601, b = -0.2673116848852909/n\n",
            "Loss: [1.69298583]\n",
            "epoch 70, m = 1.695813761169803, b = -0.27001420309081947/n\n",
            "Loss: [1.66906117]\n",
            "epoch 71, m = 1.7067681363446876, b = -0.26636274469919125/n\n",
            "Loss: [1.64602274]\n",
            "epoch 72, m = 1.7008811952250802, b = -0.26930621525899495/n\n",
            "Loss: [1.62346215]\n",
            "epoch 73, m = 1.7008811952250802, b = -0.28392009095381504/n\n",
            "Loss: [1.60853682]\n",
            "epoch 74, m = 1.692541973139655, b = -0.29225931303924035/n\n",
            "Loss: [1.58914925]\n",
            "epoch 75, m = 1.6888289878100522, b = -0.2941158057040417/n\n",
            "Loss: [1.56807548]\n",
            "epoch 76, m = 1.7024867183464854, b = -0.289563228858564/n\n",
            "Loss: [1.54812468]\n",
            "epoch 77, m = 1.7226457194023843, b = -0.309722229914463/n\n",
            "Loss: [1.54121349]\n",
            "epoch 78, m = 1.7419983604160474, b = -0.3290748709281261/n\n",
            "Loss: [1.53345834]\n",
            "epoch 79, m = 1.7481831477968464, b = -0.3270132751345264/n\n",
            "Loss: [1.51418198]\n",
            "epoch 80, m = 1.7397597503436, b = -0.33543667258777277/n\n",
            "Loss: [1.497472]\n",
            "epoch 81, m = 1.7467291956370183, b = -0.3331135241566333/n\n",
            "Loss: [1.47915127]\n",
            "epoch 82, m = 1.7651323412411453, b = -0.3515166697607603/n\n",
            "Loss: [1.47143832]\n",
            "epoch 83, m = 1.757982420732284, b = -0.3550916300151909/n\n",
            "Loss: [1.4540951]\n",
            "epoch 84, m = 1.7628510828013844, b = -0.3534687426588241/n\n",
            "Loss: [1.43686283]\n",
            "epoch 85, m = 1.7559617458836265, b = -0.356913411117703/n\n",
            "Loss: [1.42030755]\n",
            "epoch 86, m = 1.7497613426576446, b = -0.36001361273069404/n\n",
            "Loss: [1.40407175]\n",
            "epoch 87, m = 1.7419663880591056, b = -0.36780856732923306/n\n",
            "Loss: [1.389679]\n",
            "epoch 88, m = 1.7373214197075466, b = -0.37013105150501263/n\n",
            "Loss: [1.37404043]\n",
            "epoch 89, m = 1.7331409481911433, b = -0.37222128726321424/n\n",
            "Loss: [1.3587245]\n",
            "epoch 90, m = 1.7435088547525304, b = -0.36876531840941856/n\n",
            "Loss: [1.34395934]\n",
            "epoch 91, m = 1.7435088547525304, b = -0.3813900120412302/n\n",
            "Loss: [1.3335692]\n",
            "epoch 92, m = 1.761010877416655, b = -0.39889203470535495/n\n",
            "Loss: [1.32739782]\n",
            "epoch 93, m = 1.7679624415639785, b = -0.39657484665624715/n\n",
            "Loss: [1.31326906]\n",
            "epoch 94, m = 1.7605346896658238, b = -0.4040025985544018/n\n",
            "Loss: [1.30076544]\n",
            "epoch 95, m = 1.7772439439014194, b = -0.4207118527899973/n\n",
            "Loss: [1.29442052]\n",
            "epoch 96, m = 1.7772439439014194, b = -0.43229761573419734/n\n",
            "Loss: [1.28443254]\n",
            "epoch 97, m = 1.793053112708707, b = -0.448106784541485/n\n",
            "Loss: [1.27763246]\n",
            "epoch 98, m = 1.797189959493629, b = -0.44672783561317775/n\n",
            "Loss: [1.2646439]\n",
            "epoch 99, m = 1.8123116035914928, b = -0.4618494797110416/n\n",
            "Loss: [1.25764407]\n",
            "epoch 100, m = 1.826828381925442, b = -0.47636625804499094/n\n",
            "Loss: [1.25033605]\n",
            "epoch 101, m = 1.826828381925442, b = -0.48683893288409114/n\n",
            "Loss: [1.24067126]\n",
            "epoch 102, m = 1.8405550356292515, b = -0.5005655865879005/n\n",
            "Loss: [1.23312598]\n",
            "epoch 103, m = 1.8337552466484244, b = -0.5073653755687275/n\n",
            "Loss: [1.22227614]\n",
            "epoch 104, m = 1.8337552466484244, b = -0.5172180680573529/n\n",
            "Loss: [1.21285703]\n",
            "epoch 105, m = 1.8467357803543087, b = -0.5301986017632374/n\n",
            "Loss: [1.20531778]\n",
            "epoch 106, m = 1.8404050367824873, b = -0.5365293453350588/n\n",
            "Loss: [1.1948921]\n",
            "epoch 107, m = 1.8346338076532906, b = -0.5394149598996572/n\n",
            "Loss: [1.18391944]\n",
            "epoch 108, m = 1.8471528323022317, b = -0.5519339845485982/n\n",
            "Loss: [1.17658514]\n",
            "epoch 109, m = 1.8414579650999972, b = -0.5547814181497155/n\n",
            "Loss: [1.16597674]\n",
            "epoch 110, m = 1.853533177435003, b = -0.5668566304847212/n\n",
            "Loss: [1.15869083]\n",
            "epoch 111, m = 1.8477996464959974, b = -0.5725901614237269/n\n",
            "Loss: [1.14899257]\n",
            "epoch 112, m = 1.8428792812332666, b = -0.5750503440550923/n\n",
            "Loss: [1.1388688]\n",
            "epoch 113, m = 1.8428792812332666, b = -0.5835493371739904/n\n",
            "Loss: [1.13038839]\n",
            "epoch 114, m = 1.8543507088651214, b = -0.5950207648058452/n\n",
            "Loss: [1.12335853]\n",
            "epoch 115, m = 1.8543507088651214, b = -0.6031203495097283/n\n",
            "Loss: [1.11501635]\n",
            "epoch 116, m = 1.8543507088651214, b = -0.6110579425195337/n\n",
            "Loss: [1.10676202]\n",
            "epoch 117, m = 1.8543507088651214, b = -0.6188367836691431/n\n",
            "Loss: [1.09859547]\n",
            "epoch 118, m = 1.8507561235026775, b = -0.620634076350365/n\n",
            "Loss: [1.08935378]\n",
            "epoch 119, m = 1.8461536825596312, b = -0.6252365172934113/n\n",
            "Loss: [1.08064455]\n",
            "epoch 120, m = 1.8513602107365021, b = -0.623501007901121/n\n",
            "Loss: [1.07170193]\n",
            "epoch 121, m = 1.8481914341936267, b = -0.6250853961725586/n\n",
            "Loss: [1.06289676]\n",
            "epoch 122, m = 1.8481914341936267, b = -0.6325836882491075/n\n",
            "Loss: [1.05533663]\n",
            "epoch 123, m = 1.8438792792747363, b = -0.6368958431679979/n\n",
            "Loss: [1.0471346]\n",
            "epoch 124, m = 1.8542637768258816, b = -0.6472803407191432/n\n",
            "Loss: [1.04086411]\n",
            "epoch 125, m = 1.8542637768258816, b = -0.6543347339047604/n\n",
            "Loss: [1.03353249]\n",
            "epoch 126, m = 1.8597563810315085, b = -0.6525038658362181/n\n",
            "Loss: [1.02539636]\n",
            "epoch 127, m = 1.86415046439601, b = -0.6510391713813842/n\n",
            "Loss: [1.0173646]\n",
            "epoch 128, m = 1.86415046439601, b = -0.6580183879537566/n\n",
            "Loss: [1.0103678]\n",
            "epoch 129, m = 1.8737070873490147, b = -0.6675750109067612/n\n",
            "Loss: [1.00430543]\n",
            "epoch 130, m = 1.8828814453838991, b = -0.6767493689416457/n\n",
            "Loss: [0.99819864]\n",
            "epoch 131, m = 1.8828814453838991, b = -0.6832143815628128/n\n",
            "Loss: [0.99137644]\n",
            "epoch 132, m = 1.8795795050156998, b = -0.6848653517469124/n\n",
            "Loss: [0.98391764]\n",
            "epoch 133, m = 1.8766077586843204, b = -0.6863512249126021/n\n",
            "Loss: [0.97656126]\n",
            "epoch 134, m = 1.8766077586843204, b = -0.6926242004143501/n\n",
            "Loss: [0.97000763]\n",
            "epoch 135, m = 1.8741841060061488, b = -0.6938360267534359/n\n",
            "Loss: [0.96284959]\n",
            "epoch 136, m = 1.8720028185957944, b = -0.6949266704586131/n\n",
            "Loss: [0.95579168]\n",
            "epoch 137, m = 1.8806642288147062, b = -0.703588080677525/n\n",
            "Loss: [0.95018407]\n",
            "epoch 138, m = 1.8806642288147062, b = -0.7095163190639745/n\n",
            "Loss: [0.94393535]\n",
            "epoch 139, m = 1.8772412706196915, b = -0.7129392772589891/n\n",
            "Loss: [0.93735518]\n",
            "epoch 140, m = 1.8821141985436864, b = -0.7113149679509908/n\n",
            "Loss: [0.9307069]\n",
            "epoch 141, m = 1.8860125408828823, b = -0.7100155205045922/n\n",
            "Loss: [0.92413608]\n",
            "epoch 142, m = 1.8860125408828823, b = -0.7158152100945003/n\n",
            "Loss: [0.91822027]\n",
            "epoch 143, m = 1.8894791961296336, b = -0.7146596583455833/n\n",
            "Loss: [0.91182249]\n",
            "epoch 144, m = 1.8894791961296336, b = -0.7203664651786716/n\n",
            "Loss: [0.9060558]\n",
            "epoch 145, m = 1.8871355190464096, b = -0.7215383037202836/n\n",
            "Loss: [0.89983082]\n",
            "epoch 146, m = 1.883823574739887, b = -0.7248502480268061/n\n",
            "Loss: [0.89385542]\n",
            "epoch 147, m = 1.8882263461683158, b = -0.7233826575506632/n\n",
            "Loss: [0.8878114]\n",
            "epoch 148, m = 1.8959941660939361, b = -0.7311504774762836/n\n",
            "Loss: [0.88283191]\n",
            "epoch 149, m = 1.8935606519054726, b = -0.7323672345705153/n\n",
            "Loss: [0.87693171]\n",
            "epoch 150, m = 1.8903367835587734, b = -0.7355911029172145/n\n",
            "Loss: [0.87125872]\n",
            "epoch 151, m = 1.8885334849907602, b = -0.7364927522012211/n\n",
            "Loss: [0.86550225]\n",
            "epoch 152, m = 1.8869105162795483, b = -0.7373042365568271/n\n",
            "Loss: [0.85981899]\n",
            "epoch 153, m = 1.8854498444394576, b = -0.7380345724768724/n\n",
            "Loss: [0.85420797]\n",
            "epoch 154, m = 1.884135239783376, b = -0.7386918748049133/n\n",
            "Loss: [0.84866818]\n",
            "epoch 155, m = 1.8812263724838068, b = -0.7416007421044826/n\n",
            "Loss: [0.84332938]\n",
            "epoch 156, m = 1.8812263724838068, b = -0.746768727262393/n\n",
            "Loss: [0.83835144]\n",
            "epoch 157, m = 1.8886664704888827, b = -0.754208825267469/n\n",
            "Loss: [0.83389307]\n",
            "epoch 158, m = 1.8958089645737557, b = -0.761351319352342/n\n",
            "Loss: [0.82942247]\n",
            "epoch 159, m = 1.9026657588952338, b = -0.76820811367382/n\n",
            "Loss: [0.82494521]\n",
            "epoch 160, m = 1.9026657588952338, b = -0.7728439514003437/n\n",
            "Loss: [0.8201251]\n",
            "epoch 161, m = 1.901366256239629, b = -0.7734937027281461/n\n",
            "Loss: [0.81503771]\n",
            "epoch 162, m = 1.901366256239629, b = -0.7780238286735832/n\n",
            "Loss: [0.81032331]\n",
            "epoch 163, m = 1.8988994076883081, b = -0.7804906772249042/n\n",
            "Loss: [0.80544534]\n",
            "epoch 164, m = 1.89653123307904, b = -0.7828588518341723/n\n",
            "Loss: [0.80061958]\n",
            "epoch 165, m = 1.8961230885060838, b = -0.7830629241206504/n\n",
            "Loss: [0.79576797]\n",
            "epoch 166, m = 1.8961230885060838, b = -0.7874016656382373/n\n",
            "Loss: [0.79125769]\n",
            "epoch 167, m = 1.9020650325132828, b = -0.7854210176358376/n\n",
            "Loss: [0.78657835]\n",
            "epoch 168, m = 1.9083153115103004, b = -0.7916712966328552/n\n",
            "Loss: [0.78247767]\n",
            "epoch 169, m = 1.9059824312127516, b = -0.794004176930404/n\n",
            "Loss: [0.77792813]\n",
            "epoch 170, m = 1.9037428661271045, b = -0.796243742016051/n\n",
            "Loss: [0.77342585]\n",
            "epoch 171, m = 1.9097431339642414, b = -0.8022440098531879/n\n",
            "Loss: [0.76942925]\n",
            "epoch 172, m = 1.9075931514820204, b = -0.804393992335409/n\n",
            "Loss: [0.76502301]\n",
            "epoch 173, m = 1.907161459056875, b = -0.8046098385479816/n\n",
            "Loss: [0.76060159]\n",
            "epoch 174, m = 1.9051104266466972, b = -0.8066608709581595/n\n",
            "Loss: [0.75629075]\n",
            "epoch 175, m = 1.9031414355329264, b = -0.8086298620719303/n\n",
            "Loss: [0.75202448]\n",
            "epoch 176, m = 1.9089060095808292, b = -0.8143944361198332/n\n",
            "Loss: [0.74822363]\n",
            "epoch 177, m = 1.9087693062591562, b = -0.8144627877806697/n\n",
            "Loss: [0.74399645]\n",
            "epoch 178, m = 1.9140585983993483, b = -0.8126996904006057/n\n",
            "Loss: [0.73986035]\n",
            "epoch 179, m = 1.9134418981434247, b = -0.8130080405285676/n\n",
            "Loss: [0.73572838]\n",
            "epoch 180, m = 1.9114332209911276, b = -0.8150167176808647/n\n",
            "Loss: [0.73169704]\n",
            "epoch 181, m = 1.9162762442735766, b = -0.8134023765867151/n\n",
            "Loss: [0.72769051]\n",
            "epoch 182, m = 1.9162762442735766, b = -0.8171343290549808/n\n",
            "Loss: [0.72388352]\n",
            "epoch 183, m = 1.9203745800476317, b = -0.8157682171302958/n\n",
            "Loss: [0.71995337]\n",
            "epoch 184, m = 1.9236532486668758, b = -0.8146753275905478/n\n",
            "Loss: [0.71605681]\n",
            "epoch 185, m = 1.9288866771417272, b = -0.8199087560653994/n\n",
            "Loss: [0.71255635]\n",
            "epoch 186, m = 1.927372093213005, b = -0.8206660480297605/n\n",
            "Loss: [0.70873311]\n",
            "epoch 187, m = 1.927372093213005, b = -0.8242527270691653/n\n",
            "Loss: [0.70511507]\n",
            "epoch 188, m = 1.9323395968073616, b = -0.8292202306635219/n\n",
            "Loss: [0.7016926]\n",
            "epoch 189, m = 1.937108400257944, b = -0.8339890341141042/n\n",
            "Loss: [0.69828076]\n",
            "epoch 190, m = 1.9354992896018726, b = -0.8347935894421399/n\n",
            "Loss: [0.69461411]\n",
            "epoch 191, m = 1.9400934320209924, b = -0.8393877318612596/n\n",
            "Loss: [0.69125365]\n",
            "epoch 192, m = 1.9400934320209924, b = -0.8425999772240343/n\n",
            "Loss: [0.68778772]\n",
            "epoch 193, m = 1.9381435629250532, b = -0.8445498463199735/n\n",
            "Loss: [0.6842733]\n",
            "epoch 194, m = 1.9381435629250532, b = -0.847658849393574/n\n",
            "Loss: [0.68087068]\n",
            "epoch 195, m = 1.9424275146786807, b = -0.8519428011472016/n\n",
            "Loss: [0.67761432]\n",
            "epoch 196, m = 1.940617820408051, b = -0.8537524954178312/n\n",
            "Loss: [0.67419888]\n",
            "epoch 197, m = 1.940617820408051, b = -0.8566774455094746/n\n",
            "Loss: [0.67088512]\n",
            "epoch 198, m = 1.940617820408051, b = -0.8595438965992851/n\n",
            "Loss: [0.66760056]\n",
            "epoch 199, m = 1.9446145860679043, b = -0.8635406622591384/n\n",
            "Loss: [0.66444646]\n",
            "epoch 200, m = 1.9435870456728375, b = -0.8640544324566718/n\n",
            "Loss: [0.66112753]\n",
            "epoch 201, m = 1.945584643399127, b = -0.8633885665479086/n\n",
            "Loss: [0.65784385]\n",
            "epoch 202, m = 1.945584643399127, b = -0.8661207952169505/n\n",
            "Loss: [0.65467959]\n",
            "epoch 203, m = 1.9473466553003012, b = -0.8655334579165591/n\n",
            "Loss: [0.65145881]\n",
            "epoch 204, m = 1.9487562648212404, b = -0.8650635880762461/n\n",
            "Loss: [0.64826809]\n",
            "epoch 205, m = 1.9524798677632906, b = -0.8687871910182964/n\n",
            "Loss: [0.6452749]\n",
            "epoch 206, m = 1.9510329659829593, b = -0.8695106419084621/n\n",
            "Loss: [0.64214885]\n",
            "epoch 207, m = 1.949730754380661, b = -0.8701617477096112/n\n",
            "Loss: [0.6390518]\n",
            "epoch 208, m = 1.9533329043388556, b = -0.8737638976678057/n\n",
            "Loss: [0.63613539]\n",
            "epoch 209, m = 1.9520168278984593, b = -0.8744219358880039/n\n",
            "Loss: [0.63309686]\n",
            "epoch 210, m = 1.9508323591021026, b = -0.8750141702861822/n\n",
            "Loss: [0.63008629]\n",
            "epoch 211, m = 1.9497663371853817, b = -0.8755471812445427/n\n",
            "Loss: [0.62710346]\n",
            "epoch 212, m = 1.948281954066565, b = -0.8770315643633595/n\n",
            "Loss: [0.62417141]\n",
            "epoch 213, m = 1.948281954066565, b = -0.8794909330760923/n\n",
            "Loss: [0.62131202]\n",
            "epoch 214, m = 1.9475990350642836, b = -0.879832392577233/n\n",
            "Loss: [0.61841006]\n",
            "epoch 215, m = 1.9475990350642836, b = -0.8822357447256883/n\n",
            "Loss: [0.61560089]\n",
            "epoch 216, m = 1.9470805420481685, b = -0.8824949912337459/n\n",
            "Loss: [0.61275167]\n",
            "epoch 217, m = 1.9504890313825303, b = -0.8859034805681075/n\n",
            "Loss: [0.61006177]\n",
            "epoch 218, m = 1.9537611811435176, b = -0.8891756303290947/n\n",
            "Loss: [0.60738611]\n",
            "epoch 219, m = 1.9530273118652, b = -0.8895425649682536/n\n",
            "Loss: [0.60461419]\n",
            "epoch 220, m = 1.9548549496275591, b = -0.8889333523808005/n\n",
            "Loss: [0.60187017]\n",
            "epoch 221, m = 1.9579791835873919, b = -0.8920575863406334/n\n",
            "Loss: [0.59925719]\n",
            "epoch 222, m = 1.9570231523540258, b = -0.8925356019573164/n\n",
            "Loss: [0.5965604]\n",
            "epoch 223, m = 1.960031977267799, b = -0.8955444268710896/n\n",
            "Loss: [0.59398674]\n",
            "epoch 224, m = 1.9587422262598648, b = -0.8968341778790238/n\n",
            "Loss: [0.59135358]\n",
            "epoch 225, m = 1.9587422262598648, b = -0.8988974943214433/n\n",
            "Loss: [0.58877264]\n",
            "epoch 226, m = 1.9587422262598648, b = -0.9009195444350144/n\n",
            "Loss: [0.58621268]\n",
            "epoch 227, m = 1.9587422262598648, b = -0.9029011535463142/n\n",
            "Loss: [0.58367349]\n",
            "epoch 228, m = 1.9576254048055939, b = -0.9040179750005852/n\n",
            "Loss: [0.5811272]\n",
            "epoch 229, m = 1.9594939104406222, b = -0.9033951397889092/n\n",
            "Loss: [0.57859376]\n",
            "epoch 230, m = 1.9594939104406222, b = -0.905327236993131/n\n",
            "Loss: [0.57611871]\n",
            "epoch 231, m = 1.961104640780898, b = -0.9047903268797057/n\n",
            "Loss: [0.57362781]\n",
            "epoch 232, m = 1.9623932250531189, b = -0.9043607987889655/n\n",
            "Loss: [0.57115726]\n",
            "epoch 233, m = 1.9623932250531189, b = -0.9062735828131862/n\n",
            "Loss: [0.5687452]\n",
            "epoch 234, m = 1.9623932250531189, b = -0.9081481111569224/n\n",
            "Loss: [0.56635221]\n",
            "epoch 235, m = 1.9613083227751948, b = -0.9092330134348463/n\n",
            "Loss: [0.56395472]\n",
            "epoch 236, m = 1.9628268054817506, b = -0.9087268525326611/n\n",
            "Loss: [0.5615678]\n",
            "epoch 237, m = 1.964041591646995, b = -0.9083219238109129/n\n",
            "Loss: [0.55920004]\n",
            "epoch 238, m = 1.9650134205791907, b = -0.9079979808335144/n\n",
            "Loss: [0.55685156]\n",
            "epoch 239, m = 1.9650134205791907, b = -0.9098380212168441/n\n",
            "Loss: [0.55455706]\n",
            "epoch 240, m = 1.9642058677815293, b = -0.9102417976156748/n\n",
            "Loss: [0.5522481]\n",
            "epoch 241, m = 1.9667169144735852, b = -0.9127528443077307/n\n",
            "Loss: [0.55002202]\n",
            "epoch 242, m = 1.9674730405268037, b = -0.9125008022899912/n\n",
            "Loss: [0.54774986]\n",
            "epoch 243, m = 1.9698735636704678, b = -0.9149013254336553/n\n",
            "Loss: [0.54555503]\n",
            "epoch 244, m = 1.9698735636704678, b = -0.9166032989249823/n\n",
            "Loss: [0.54334883]\n",
            "epoch 245, m = 1.9721440264185588, b = -0.9188737616730732/n\n",
            "Loss: [0.54118368]\n",
            "epoch 246, m = 1.9722905273636027, b = -0.9188249280247253/n\n",
            "Loss: [0.53898377]\n",
            "epoch 247, m = 1.9722905273636027, b = -0.9204484294642308/n\n",
            "Loss: [0.53682833]\n",
            "epoch 248, m = 1.974435748227046, b = -0.9225936503276742/n\n",
            "Loss: [0.53471009]\n",
            "epoch 249, m = 1.9743929325658383, b = -0.9226079222147434/n\n",
            "Loss: [0.53256266]\n",
            "epoch 250, m = 1.9733572323588164, b = -0.9236436224217653/n\n",
            "Loss: [0.53044314]\n",
            "epoch 251, m = 1.9735715478795355, b = -0.9235721839148591/n\n",
            "Loss: [0.52832987]\n",
            "epoch 252, m = 1.9725715606002419, b = -0.9245721711941526/n\n",
            "Loss: [0.52624324]\n",
            "epoch 253, m = 1.9716115728121202, b = -0.9255321589822744/n\n",
            "Loss: [0.52417234]\n",
            "epoch 254, m = 1.9706899845355232, b = -0.9264537472588713/n\n",
            "Loss: [0.52211702]\n",
            "epoch 255, m = 1.9700929356630363, b = -0.9267522716951148/n\n",
            "Loss: [0.52007038]\n",
            "epoch 256, m = 1.9721560315158733, b = -0.9288153675479517/n\n",
            "Loss: [0.51808042]\n",
            "epoch 257, m = 1.9721560315158733, b = -0.9302390601969927/n\n",
            "Loss: [0.51608426]\n",
            "epoch 258, m = 1.9741081296816159, b = -0.9321911583627354/n\n",
            "Loss: [0.51412086]\n",
            "epoch 259, m = 1.973467125641596, b = -0.9325116603827452/n\n",
            "Loss: [0.51213683]\n",
            "epoch 260, m = 1.972648016336419, b = -0.9333307696879223/n\n",
            "Loss: [0.51017352]\n",
            "epoch 261, m = 1.9721694058170225, b = -0.9335700749476206/n\n",
            "Loss: [0.50821938]\n",
            "epoch 262, m = 1.9731931172668158, b = -0.9332288377976895/n\n",
            "Loss: [0.50628073]\n",
            "epoch 263, m = 1.9750646781655257, b = -0.9351003986963994/n\n",
            "Loss: [0.504389]\n",
            "epoch 264, m = 1.9768613766282872, b = -0.9368970971591609/n\n",
            "Loss: [0.50250901]\n",
            "epoch 265, m = 1.9768613766282872, b = -0.9381591552159777/n\n",
            "Loss: [0.50062777]\n",
            "epoch 266, m = 1.9768613766282872, b = -0.9393959721116582/n\n",
            "Loss: [0.49876009]\n",
            "epoch 267, m = 1.977390087161895, b = -0.9392197352671222/n\n",
            "Loss: [0.49689237]\n",
            "epoch 268, m = 1.9767676695996284, b = -0.9395309440482555/n\n",
            "Loss: [0.49503919]\n",
            "epoch 269, m = 1.9784416973266707, b = -0.9412049717752978/n\n",
            "Loss: [0.49322494]\n",
            "epoch 270, m = 1.9784416973266707, b = -0.9423808723397918/n\n",
            "Loss: [0.49141099]\n",
            "epoch 271, m = 1.977720480826933, b = -0.9431020888395294/n\n",
            "Loss: [0.48960246]\n",
            "epoch 272, m = 1.977028112987185, b = -0.9437944566792774/n\n",
            "Loss: [0.48780686]\n",
            "epoch 273, m = 1.9763634398610268, b = -0.9444591298054356/n\n",
            "Loss: [0.48602406]\n",
            "epoch 274, m = 1.975725353659915, b = -0.9450972160065474/n\n",
            "Loss: [0.48425397]\n",
            "epoch 275, m = 1.9754712140073838, b = -0.945224285832813/n\n",
            "Loss: [0.48249319]\n",
            "epoch 276, m = 1.9770573040105799, b = -0.9468103758360091/n\n",
            "Loss: [0.48076782]\n",
            "epoch 277, m = 1.977995611838836, b = -0.9464976065599238/n\n",
            "Loss: [0.47903307]\n",
            "epoch 278, m = 1.9773656517332578, b = -0.947127566665502/n\n",
            "Loss: [0.4773135]\n",
            "epoch 279, m = 1.9788757873652827, b = -0.9486377022975269/n\n",
            "Loss: [0.47562314]\n",
            "epoch 280, m = 1.9788757873652827, b = -0.9496649482515763/n\n",
            "Loss: [0.4739339]\n",
            "epoch 281, m = 1.9785523223061232, b = -0.9498266807811561/n\n",
            "Loss: [0.47224754]\n",
            "epoch 282, m = 1.9785523223061232, b = -0.9508301471655329/n\n",
            "Loss: [0.47058183]\n",
            "epoch 283, m = 1.9783013424082547, b = -0.9509556371144672/n\n",
            "Loss: [0.46891914]\n",
            "epoch 284, m = 1.9797162028178004, b = -0.9523704975240127/n\n",
            "Loss: [0.46728563]\n",
            "epoch 285, m = 1.980509516162037, b = -0.9521060597426004/n\n",
            "Loss: [0.46564665]\n",
            "epoch 286, m = 1.9818572046439442, b = -0.9534537482245077/n\n",
            "Loss: [0.46403439]\n",
            "epoch 287, m = 1.9812891355155555, b = -0.9540218173528964/n\n",
            "Loss: [0.46242036]\n",
            "epoch 288, m = 1.9812891355155555, b = -0.9549413810058385/n\n",
            "Loss: [0.46082207]\n",
            "epoch 289, m = 1.9807621804253612, b = -0.9554683360960328/n\n",
            "Loss: [0.45922993]\n",
            "epoch 290, m = 1.9805199394351736, b = -0.9555894565911266/n\n",
            "Loss: [0.45764651]\n",
            "epoch 291, m = 1.9800213297782927, b = -0.9560880662480076/n\n",
            "Loss: [0.45607597]\n",
            "epoch 292, m = 1.979542664507687, b = -0.9565667315186133/n\n",
            "Loss: [0.45451603]\n",
            "epoch 293, m = 1.980820476587161, b = -0.9578445435980872/n\n",
            "Loss: [0.45297871]\n",
            "epoch 294, m = 1.9820471761834562, b = -0.9590712431943823/n\n",
            "Loss: [0.45145077]\n",
            "epoch 295, m = 1.982822959062097, b = -0.958812648901502/n\n",
            "Loss: [0.44992099]\n",
            "epoch 296, m = 1.9834435853650096, b = -0.9586057734671978/n\n",
            "Loss: [0.44840135]\n",
            "epoch 297, m = 1.9846025981883655, b = -0.9597647862905536/n\n",
            "Loss: [0.44690289]\n",
            "epoch 298, m = 1.9846025981883655, b = -0.9605694905647425/n\n",
            "Loss: [0.44540865]\n",
            "epoch 299, m = 1.9856991564133033, b = -0.9616660487896803/n\n",
            "Loss: [0.44392904]\n",
            "epoch 300, m = 1.9852184942608309, b = -0.9621467109421528/n\n",
            "Loss: [0.4424512]\n",
            "epoch 301, m = 1.9852184942608309, b = -0.9629037767233097/n\n",
            "Loss: [0.44098602]\n",
            "epoch 302, m = 1.9852184942608309, b = -0.9636457011888435/n\n",
            "Loss: [0.43953036]\n",
            "epoch 303, m = 1.9852184942608309, b = -0.9643727871650667/n\n",
            "Loss: [0.43808413]\n",
            "epoch 304, m = 1.9848015801189156, b = -0.9647897013069819/n\n",
            "Loss: [0.43664449]\n",
            "epoch 305, m = 1.9858097544903976, b = -0.965797875678464/n\n",
            "Loss: [0.4352212]\n",
            "epoch 306, m = 1.986311871222834, b = -0.9656305034343186/n\n",
            "Loss: [0.43379914]\n",
            "epoch 307, m = 1.986713564608783, b = -0.9654966056390022/n\n",
            "Loss: [0.43238626]\n",
            "epoch 308, m = 1.9876693612038272, b = -0.9664524022340465/n\n",
            "Loss: [0.43098982]\n",
            "epoch 309, m = 1.9872450220244315, b = -0.9668767414134422/n\n",
            "Loss: [0.42959649]\n",
            "epoch 310, m = 1.988162586755674, b = -0.9677943061446846/n\n",
            "Loss: [0.42821748]\n",
            "epoch 311, m = 1.988162586755674, b = -0.9684384200217909/n\n",
            "Loss: [0.42684391]\n",
            "epoch 312, m = 1.9877681034209964, b = -0.9688329033564685/n\n",
            "Loss: [0.42547707]\n",
            "epoch 313, m = 1.9873893994197058, b = -0.9692116073577591/n\n",
            "Loss: [0.42411887]\n",
            "epoch 314, m = 1.9882573792841565, b = -0.9700795872222099/n\n",
            "Loss: [0.42277417]\n",
            "epoch 315, m = 1.9882573792841565, b = -0.9706779954777657/n\n",
            "Loss: [0.42143487]\n",
            "epoch 316, m = 1.989078671788918, b = -0.9714992879825273/n\n",
            "Loss: [0.42010655]\n",
            "epoch 317, m = 1.989867112593489, b = -0.9722877287870983/n\n",
            "Loss: [0.4187862]\n",
            "epoch 318, m = 1.989867112593489, b = -0.9728419742113564/n\n",
            "Loss: [0.41747167]\n",
            "epoch 319, m = 1.9895914225544642, b = -0.9729798192308688/n\n",
            "Loss: [0.41616313]\n",
            "epoch 320, m = 1.9903399977187575, b = -0.9737283943951622/n\n",
            "Loss: [0.414867]\n",
            "epoch 321, m = 1.9905025017930909, b = -0.9736742263703845/n\n",
            "Loss: [0.4135746]\n",
            "epoch 322, m = 1.9901659362846367, b = -0.9740107918788387/n\n",
            "Loss: [0.41229109]\n",
            "epoch 323, m = 1.9903767152661325, b = -0.9739405322183401/n\n",
            "Loss: [0.41101469]\n",
            "epoch 324, m = 1.991090370316443, b = -0.9746541872686506/n\n",
            "Loss: [0.40975005]\n",
            "epoch 325, m = 1.991090370316443, b = -0.9751611035232776/n\n",
            "Loss: [0.40849126]\n",
            "epoch 326, m = 1.99120376987088, b = -0.9751233036717986/n\n",
            "Loss: [0.40723823]\n",
            "epoch 327, m = 1.9918772284000263, b = -0.975796762200945/n\n",
            "Loss: [0.40599632]\n",
            "epoch 328, m = 1.9918871330200782, b = -0.9757934606609276/n\n",
            "Loss: [0.40475853]\n",
            "epoch 329, m = 1.992533521146458, b = -0.9764398487873075/n\n",
            "Loss: [0.40353143]\n",
            "epoch 330, m = 1.9921884334062339, b = -0.9766123926574196/n\n",
            "Loss: [0.40230883]\n",
            "epoch 331, m = 1.9921884334062339, b = -0.9770801448042712/n\n",
            "Loss: [0.40109505]\n",
            "epoch 332, m = 1.9922193240813681, b = -0.9770698479125598/n\n",
            "Loss: [0.39988694]\n",
            "epoch 333, m = 1.9922193240813681, b = -0.9775284509543086/n\n",
            "Loss: [0.39868765]\n",
            "epoch 334, m = 1.9928243685806546, b = -0.9781334954535951/n\n",
            "Loss: [0.39749672]\n",
            "epoch 335, m = 1.9934052112999696, b = -0.9787143381729101/n\n",
            "Loss: [0.39631268]\n",
            "epoch 336, m = 1.9930813679228885, b = -0.9788762598614507/n\n",
            "Loss: [0.39513337]\n",
            "epoch 337, m = 1.9930592972884555, b = -0.978883616739595/n\n",
            "Loss: [0.39396087]\n",
            "epoch 338, m = 1.9927757836774784, b = -0.9791671303505722/n\n",
            "Loss: [0.3927959]\n",
            "epoch 339, m = 1.9927757836774784, b = -0.9795837877435608/n\n",
            "Loss: [0.39163849]\n",
            "epoch 340, m = 1.9925119437588001, b = -0.9798476276622392/n\n",
            "Loss: [0.39048712]\n",
            "epoch 341, m = 1.9923048933645857, b = -0.9799511528593464/n\n",
            "Loss: [0.38934208]\n",
            "epoch 342, m = 1.9921185480097927, b = -0.9800443255367429/n\n",
            "Loss: [0.38820371]\n",
            "epoch 343, m = 1.9923398689002345, b = -0.9799705519065957/n\n",
            "Loss: [0.38707196]\n",
            "epoch 344, m = 1.9928936604840979, b = -0.980524343490459/n\n",
            "Loss: [0.38594898]\n",
            "epoch 345, m = 1.9928936604840979, b = -0.9809138566206499/n\n",
            "Loss: [0.38483139]\n",
            "epoch 346, m = 1.9930276329941994, b = -0.9808691991172828/n\n",
            "Loss: [0.38371918]\n",
            "epoch 347, m = 1.9930276329941994, b = -0.9812518151349371/n\n",
            "Loss: [0.38261441]\n",
            "epoch 348, m = 1.9927921166370142, b = -0.9814873314921223/n\n",
            "Loss: [0.38151534]\n",
            "epoch 349, m = 1.9925660209341163, b = -0.9817134271950202/n\n",
            "Loss: [0.38042254]\n",
            "epoch 350, m = 1.9924292763471878, b = -0.9817817994884844/n\n",
            "Loss: [0.37933565]\n",
            "epoch 351, m = 1.992698914574003, b = -0.981691920079546/n\n",
            "Loss: [0.37825498]\n",
            "epoch 352, m = 1.992478774684114, b = -0.9819120599694351/n\n",
            "Loss: [0.37718074]\n",
            "epoch 353, m = 1.9923569551081621, b = -0.981972969757411/n\n",
            "Loss: [0.37611227]\n",
            "epoch 354, m = 1.9926510813741376, b = -0.9818749276687525/n\n",
            "Loss: [0.37504987]\n",
            "epoch 355, m = 1.99316056119328, b = -0.9823844074878947/n\n",
            "Loss: [0.37399522]\n",
            "epoch 356, m = 1.99316056119328, b = -0.9827367193381368/n\n",
            "Loss: [0.37294554]\n",
            "epoch 357, m = 1.9936426155826517, b = -0.9832187737275084/n\n",
            "Loss: [0.3719025]\n",
            "epoch 358, m = 1.9936426155826517, b = -0.9835543982529583/n\n",
            "Loss: [0.37086446]\n",
            "epoch 359, m = 1.9940986753059395, b = -0.9840104579762461/n\n",
            "Loss: [0.36983286]\n",
            "epoch 360, m = 1.9939311996005142, b = -0.9840941958289587/n\n",
            "Loss: [0.36880559]\n",
            "epoch 361, m = 1.9937804714656315, b = -0.9841695598964001/n\n",
            "Loss: [0.36778401]\n",
            "epoch 362, m = 1.9939501601956018, b = -0.98411299698641/n\n",
            "Loss: [0.36676805]\n",
            "epoch 363, m = 1.993753416931418, b = -0.9843097402505938/n\n",
            "Loss: [0.36575794]\n",
            "epoch 364, m = 1.9936255331869284, b = -0.9843736821228386/n\n",
            "Loss: [0.36475314]\n",
            "epoch 365, m = 1.9934404961656467, b = -0.9845587191441204/n\n",
            "Loss: [0.36375405]\n",
            "epoch 366, m = 1.9933476052381598, b = -0.9846051646078638/n\n",
            "Loss: [0.3627602]\n",
            "epoch 367, m = 1.9937885498412393, b = -0.9850461092109434/n\n",
            "Loss: [0.36177308]\n",
            "epoch 368, m = 1.9940093774224728, b = -0.9849725000171988/n\n",
            "Loss: [0.36079003]\n",
            "epoch 369, m = 1.9944297398736792, b = -0.9853928624684054/n\n",
            "Loss: [0.35981348]\n",
            "epoch 370, m = 1.9944297398736792, b = -0.9856850052190373/n\n",
            "Loss: [0.35884159]\n",
            "epoch 371, m = 1.9944297398736792, b = -0.9859713051146566/n\n",
            "Loss: [0.35787491]\n",
            "epoch 372, m = 1.9942605711784989, b = -0.986140473809837/n\n",
            "Loss: [0.35691308]\n",
            "epoch 373, m = 1.9940981692311257, b = -0.9863028757572103/n\n",
            "Loss: [0.35595638]\n",
            "epoch 374, m = 1.994022430722924, b = -0.9863407450113112/n\n",
            "Loss: [0.35500464]\n",
            "epoch 375, m = 1.9942788378934764, b = -0.9862552759544604/n\n",
            "Loss: [0.35405801]\n",
            "epoch 376, m = 1.9941867419001766, b = -0.9863013239511103/n\n",
            "Loss: [0.35311638]\n",
            "epoch 377, m = 1.9940290335411952, b = -0.9864590323100916/n\n",
            "Loss: [0.35217989]\n",
            "epoch 378, m = 1.9939650721503033, b = -0.9864910130055375/n\n",
            "Loss: [0.35124821]\n",
            "epoch 379, m = 1.9943559504471864, b = -0.9868818913024208/n\n",
            "Loss: [0.35032244]\n",
            "epoch 380, m = 1.9947311936121943, b = -0.9872571344674286/n\n",
            "Loss: [0.34940146]\n",
            "epoch 381, m = 1.994581712429299, b = -0.9874066156503238/n\n",
            "Loss: [0.34848455]\n",
            "epoch 382, m = 1.9949419458677067, b = -0.9877668490887314/n\n",
            "Loss: [0.34757313]\n",
            "epoch 383, m = 1.9947984439321271, b = -0.9879103510243109/n\n",
            "Loss: [0.34666577]\n",
            "epoch 384, m = 1.9950093450858029, b = -0.9878400506397523/n\n",
            "Loss: [0.34576302]\n",
            "epoch 385, m = 1.9949221995045288, b = -0.9878836234303894/n\n",
            "Loss: [0.34486495]\n",
            "epoch 386, m = 1.9949221995045288, b = -0.9881259509617816/n\n",
            "Loss: [0.3439719]\n",
            "epoch 387, m = 1.9952612364952025, b = -0.9884649879524554/n\n",
            "Loss: [0.34308382]\n",
            "epoch 388, m = 1.9955867120062494, b = -0.9887904634635023/n\n",
            "Loss: [0.34220027]\n",
            "epoch 389, m = 1.9958991684968543, b = -0.9891029199541073/n\n",
            "Loss: [0.3413212]\n",
            "epoch 390, m = 1.9957632435259993, b = -0.9892388449249622/n\n",
            "Loss: [0.34044614]\n",
            "epoch 391, m = 1.9958801903868173, b = -0.9891998626380228/n\n",
            "Loss: [0.33957544]\n",
            "epoch 392, m = 1.9957777696613928, b = -0.9892510730007351/n\n",
            "Loss: [0.3387092]\n",
            "epoch 393, m = 1.9960771928081502, b = -0.9895504961474926/n\n",
            "Loss: [0.33784791]\n",
            "epoch 394, m = 1.9960771928081502, b = -0.9897594862245427/n\n",
            "Loss: [0.33699071]\n",
            "epoch 395, m = 1.9963604592274964, b = -0.9900427526438889/n\n",
            "Loss: [0.33613807]\n",
            "epoch 396, m = 1.9966323949900686, b = -0.9903146884064612/n\n",
            "Loss: [0.33528971]\n",
            "epoch 397, m = 1.9965143909271217, b = -0.9903736904379347/n\n",
            "Loss: [0.33444517]\n",
            "epoch 398, m = 1.9965143909271217, b = -0.990566216629176/n\n",
            "Loss: [0.33360509]\n",
            "epoch 399, m = 1.996415888318119, b = -0.9906154679336774/n\n",
            "Loss: [0.332769]\n",
            "epoch 400, m = 1.9962998799104301, b = -0.9907314763413663/n\n",
            "Loss: [0.33193716]\n",
            "epoch 401, m = 1.9961885118390488, b = -0.9908428444127475/n\n",
            "Loss: [0.33110947]\n",
            "epoch 402, m = 1.9964478847140128, b = -0.9911022172877115/n\n",
            "Loss: [0.33028623]\n",
            "epoch 403, m = 1.9965533985027533, b = -0.9910670460247981/n\n",
            "Loss: [0.32946667]\n",
            "epoch 404, m = 1.9968009896122023, b = -0.9913146371342471/n\n",
            "Loss: [0.32865154]\n",
            "epoch 405, m = 1.996709495928596, b = -0.9913603839760502/n\n",
            "Loss: [0.32784006]\n",
            "epoch 406, m = 1.996709495928596, b = -0.9915331762965292/n\n",
            "Loss: [0.32703276]\n",
            "epoch 407, m = 1.9967937772392406, b = -0.9915050825263143/n\n",
            "Loss: [0.32622924]\n",
            "epoch 408, m = 1.9970278000439294, b = -0.9917391053310032/n\n",
            "Loss: [0.32543]\n",
            "epoch 409, m = 1.9972524619364307, b = -0.9919637672235045/n\n",
            "Loss: [0.32463463]\n",
            "epoch 410, m = 1.997468137353232, b = -0.9921794426403059/n\n",
            "Loss: [0.32384313]\n",
            "epoch 411, m = 1.9973623634589734, b = -0.9922852165345644/n\n",
            "Loss: [0.32305525]\n",
            "epoch 412, m = 1.997264783043638, b = -0.992334006742232/n\n",
            "Loss: [0.32227115]\n",
            "epoch 413, m = 1.9971769606698364, b = -0.9923779179291329/n\n",
            "Loss: [0.32149085]\n",
            "epoch 414, m = 1.9971769606698364, b = -0.9925303595705502/n\n",
            "Loss: [0.32071444]\n",
            "epoch 415, m = 1.9970840286478506, b = -0.9926232915925359/n\n",
            "Loss: [0.31994169]\n",
            "epoch 416, m = 1.9969948139067444, b = -0.9927125063336423/n\n",
            "Loss: [0.31917264]\n",
            "epoch 417, m = 1.9970984977835489, b = -0.9926779450413741/n\n",
            "Loss: [0.31840725]\n",
            "epoch 418, m = 1.9970100867287053, b = -0.9927663560962176/n\n",
            "Loss: [0.31764556]\n",
            "epoch 419, m = 1.9970100867287053, b = -0.9929110289742932/n\n",
            "Loss: [0.31688758]\n",
            "epoch 420, m = 1.9969657209493805, b = -0.9929332118639556/n\n",
            "Loss: [0.31613309]\n",
            "epoch 421, m = 1.9969657209493805, b = -0.9930745476266765/n\n",
            "Loss: [0.31538229]\n",
            "epoch 422, m = 1.9969314451784972, b = -0.9930916855121181/n\n",
            "Loss: [0.31463494]\n",
            "epoch 423, m = 1.9971309825646848, b = -0.9932912228983058/n\n",
            "Loss: [0.31389136]\n",
            "epoch 424, m = 1.9970541873713572, b = -0.9933680180916334/n\n",
            "Loss: [0.31315109]\n",
            "epoch 425, m = 1.9969804639857627, b = -0.993441741477228/n\n",
            "Loss: [0.31241429]\n",
            "epoch 426, m = 1.996909689535592, b = -0.9935125159273986/n\n",
            "Loss: [0.31168096]\n",
            "epoch 427, m = 1.9968974150098406, b = -0.9935186531902743/n\n",
            "Loss: [0.31095102]\n",
            "epoch 428, m = 1.9968863679366644, b = -0.9935241767268624/n\n",
            "Loss: [0.3102245]\n",
            "epoch 429, m = 1.9968191241124684, b = -0.9935914205510584/n\n",
            "Loss: [0.30950139]\n",
            "epoch 430, m = 1.9968172510055133, b = -0.993592357104536/n\n",
            "Loss: [0.30878162]\n",
            "epoch 431, m = 1.9967527531274938, b = -0.9936568549825555/n\n",
            "Loss: [0.30806522]\n",
            "epoch 432, m = 1.9966908351645951, b = -0.9937187729454543/n\n",
            "Loss: [0.30735213]\n",
            "epoch 433, m = 1.9969096112116953, b = -0.9936458475964209/n\n",
            "Loss: [0.30664234]\n",
            "epoch 434, m = 1.9970846320493754, b = -0.9935875073171943/n\n",
            "Loss: [0.30593581]\n",
            "epoch 435, m = 1.997061361778113, b = -0.9935991424528254/n\n",
            "Loss: [0.30523251]\n",
            "epoch 436, m = 1.9969921173916072, b = -0.9936683868393312/n\n",
            "Loss: [0.30453246]\n",
            "epoch 437, m = 1.9969921173916072, b = -0.9937950191025446/n\n",
            "Loss: [0.30383568]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-3d9bd2eaab64>:28: RuntimeWarning: divide by zero encountered in divide\n",
            "  print(f\"Loss: {loss/i}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 438, m = 1.9971763746617242, b = -0.9939792763726616/n\n",
            "Loss: [0.30314219]\n",
            "epoch 439, m = 1.9973532616410365, b = -0.9941561633519739/n\n",
            "Loss: [0.30245184]\n",
            "epoch 440, m = 1.9974790443467685, b = -0.9941142357833966/n\n",
            "Loss: [0.30176445]\n",
            "epoch 441, m = 1.997579670511354, b = -0.9940806937285348/n\n",
            "Loss: [0.30108019]\n",
            "epoch 442, m = 1.9975096909756975, b = -0.9941506732641912/n\n",
            "Loss: [0.30039904]\n",
            "epoch 443, m = 1.9974749426282095, b = -0.9941680474379352/n\n",
            "Loss: [0.29972094]\n",
            "epoch 444, m = 1.9974749426282095, b = -0.9942846864891765/n\n",
            "Loss: [0.29904597]\n",
            "epoch 445, m = 1.9974111375054289, b = -0.9943484916119572/n\n",
            "Loss: [0.29837398]\n",
            "epoch 446, m = 1.9975759449230812, b = -0.9945132990296094/n\n",
            "Loss: [0.29770513]\n",
            "epoch 447, m = 1.9977341600440275, b = -0.9946715141505555/n\n",
            "Loss: [0.29703926]\n",
            "epoch 448, m = 1.9978223020851358, b = -0.994642133470186/n\n",
            "Loss: [0.29637623]\n",
            "epoch 449, m = 1.9977822032571324, b = -0.9946621828841877/n\n",
            "Loss: [0.29571616]\n",
            "epoch 450, m = 1.9977822032571324, b = -0.994768939226504/n\n",
            "Loss: [0.29505907]\n",
            "epoch 451, m = 1.9978675430244388, b = -0.9947404926374018/n\n",
            "Loss: [0.29440484]\n",
            "epoch 452, m = 1.997935814838284, b = -0.9947177353661201/n\n",
            "Loss: [0.29375351]\n",
            "epoch 453, m = 1.998082743834196, b = -0.994864664362032/n\n",
            "Loss: [0.29310516]\n",
            "epoch 454, m = 1.9981197298057627, b = -0.9948523357048431/n\n",
            "Loss: [0.29245956]\n",
            "epoch 455, m = 1.9981197298057627, b = -0.9949552889907463/n\n",
            "Loss: [0.29181685]\n",
            "epoch 456, m = 1.9980564409894623, b = -0.9950185778070466/n\n",
            "Loss: [0.29117692]\n",
            "epoch 457, m = 1.9981949406135322, b = -0.9951570774311165/n\n",
            "Loss: [0.29053988]\n",
            "epoch 458, m = 1.9981949406135322, b = -0.9952539358824941/n\n",
            "Loss: [0.28990556]\n",
            "epoch 459, m = 1.9981361205189114, b = -0.9953127559771149/n\n",
            "Loss: [0.28927398]\n",
            "epoch 460, m = 1.998097741116483, b = -0.995331945678329/n\n",
            "Loss: [0.28864512]\n",
            "epoch 461, m = 1.99804242520772, b = -0.9953872615870921/n\n",
            "Loss: [0.28801901]\n",
            "epoch 462, m = 1.99804242520772, b = -0.9954795163553503/n\n",
            "Loss: [0.28739564]\n",
            "epoch 463, m = 1.9979911670306727, b = -0.9955307745323977/n\n",
            "Loss: [0.28677493]\n",
            "epoch 464, m = 1.9981207281994113, b = -0.9956603357011363/n\n",
            "Loss: [0.28615697]\n",
            "epoch 465, m = 1.998071520349446, b = -0.9957095435511019/n\n",
            "Loss: [0.28554159]\n",
            "epoch 466, m = 1.998195899071435, b = -0.9958339222730909/n\n",
            "Loss: [0.28492893]\n",
            "epoch 467, m = 1.998195899071435, b = -0.995917243827629/n\n",
            "Loss: [0.28431884]\n",
            "epoch 468, m = 1.998195899071435, b = -0.9959988989510764/n\n",
            "Loss: [0.28371135]\n",
            "epoch 469, m = 1.998312003110985, b = -0.9961150029906262/n\n",
            "Loss: [0.2831065]\n",
            "epoch 470, m = 1.9984234629889526, b = -0.996226462868594/n\n",
            "Loss: [0.28250421]\n",
            "epoch 471, m = 1.9983795229865453, b = -0.9962704028710011/n\n",
            "Loss: [0.28190442]\n",
            "epoch 472, m = 1.9984865244693943, b = -0.9963774043538501/n\n",
            "Loss: [0.28130723]\n",
            "epoch 473, m = 1.9984443420670834, b = -0.996419586756161/n\n",
            "Loss: [0.28071251]\n",
            "epoch 474, m = 1.998403846960865, b = -0.9964600818623794/n\n",
            "Loss: [0.2801203]\n",
            "epoch 475, m = 1.998389942478491, b = -0.9964670341035664/n\n",
            "Loss: [0.27953057]\n",
            "epoch 476, m = 1.9983514843109924, b = -0.9965054922710649/n\n",
            "Loss: [0.27894333]\n",
            "epoch 477, m = 1.9984385466712777, b = -0.9964764714843032/n\n",
            "Loss: [0.27835855]\n",
            "epoch 478, m = 1.9983993051675382, b = -0.9965157129880426/n\n",
            "Loss: [0.27777621]\n",
            "epoch 479, m = 1.9983616333239482, b = -0.9965533848316326/n\n",
            "Loss: [0.27719631]\n",
            "epoch 480, m = 1.9984633329608366, b = -0.9966550844685209/n\n",
            "Loss: [0.27661887]\n",
            "epoch 481, m = 1.9984633329608366, b = -0.9967219827791505/n\n",
            "Loss: [0.27604381]\n",
            "epoch 482, m = 1.9985596266460368, b = -0.9968182764643507/n\n",
            "Loss: [0.27547115]\n",
            "epoch 483, m = 1.9986279904376112, b = -0.9967954885338259/n\n",
            "Loss: [0.27490082]\n",
            "epoch 484, m = 1.9986279904376112, b = -0.9968595787631495/n\n",
            "Loss: [0.27433286]\n",
            "epoch 485, m = 1.9986121343531282, b = -0.9968675068053909/n\n",
            "Loss: [0.27376723]\n",
            "epoch 486, m = 1.9986121343531282, b = -0.9969301566692831/n\n",
            "Loss: [0.27320394]\n",
            "epoch 487, m = 1.9986121343531282, b = -0.9969915535358974/n\n",
            "Loss: [0.27264297]\n",
            "epoch 488, m = 1.998602825746314, b = -0.9969962078393045/n\n",
            "Loss: [0.27208427]\n",
            "epoch 489, m = 1.9985706933881737, b = -0.9970283401974447/n\n",
            "Loss: [0.27152787]\n",
            "epoch 490, m = 1.9985706933881737, b = -0.9970877733934957/n\n",
            "Loss: [0.27097375]\n",
            "epoch 491, m = 1.9985685488528597, b = -0.9970888456611527/n\n",
            "Loss: [0.27042187]\n",
            "epoch 492, m = 1.9986554009625794, b = -0.9971756977708724/n\n",
            "Loss: [0.26987227]\n",
            "epoch 493, m = 1.9986554009625794, b = -0.997232183815455/n\n",
            "Loss: [0.26932487]\n",
            "epoch 494, m = 1.9987313598182423, b = -0.9972068641969006/n\n",
            "Loss: [0.26877969]\n",
            "epoch 495, m = 1.9987921269027729, b = -0.9971866085020572/n\n",
            "Loss: [0.2682367]\n",
            "epoch 496, m = 1.9988725521946762, b = -0.9972670337939606/n\n",
            "Loss: [0.26769593]\n",
            "epoch 497, m = 1.9988725521946762, b = -0.9973216931180814/n\n",
            "Loss: [0.26715732]\n",
            "epoch 498, m = 1.9989486672884211, b = -0.9973978082118262/n\n",
            "Loss: [0.26662089]\n",
            "epoch 499, m = 1.998981775669215, b = -0.997386772084895/n\n",
            "Loss: [0.26608658]\n",
            "y = 1.998981775669215x + -0.997386772084895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Providing Data and Fitting it To the Model"
      ],
      "metadata": {
        "id": "d9lsa_xCzwUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0])\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0])"
      ],
      "metadata": {
        "id": "oQ245uwqvIVJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting\n",
        "model.fit(xs, ys, epochs=500);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TofhYCWP0PyI",
        "outputId": "b8d0c369-0906-4299-dffe-509269e5e51b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0604e-11\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0604e-11\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.0604e-11\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0604e-11\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.0604e-11\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0604e-11\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.0604e-11\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0604e-11\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0604e-11\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0604e-11\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0604e-11\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0604e-11\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0604e-11\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0604e-11\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0604e-11\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0604e-11\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0604e-11\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0604e-11\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0604e-11\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0604e-11\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0604e-11\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0604e-11\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0604e-11\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0604e-11\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0604e-11\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0604e-11\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0604e-11\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0604e-11\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0604e-11\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0604e-11\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0604e-11\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0604e-11\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0604e-11\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0604e-11\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0604e-11\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0604e-11\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0604e-11\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0604e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([10])) #It predicted very close to 19"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHMXiuXU0aDC",
        "outputId": "79f5e818-8f88-4b7a-d756-574c14d16763"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "[[18.999987]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2WjhBipt1EXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}